**Latency**

Latency refers to the delay before a transfer of data begins following an instruction for its transfer. _In a network, it's the time it takes for a data packet to travel from its source to its destination_.

**Throughput**

Throughput is the actual rate of data transfer over a network or communication channel, measured in _bits per second (bps)_ or _bytes per second (Bps)_. It represents how much data can be successfully sent and received in a given amount of time.

**DNS (Domain Name System)**

DNS is the internet's phonebook, translating human-readable domain names (like `www.example.com`) into machine-readable IP addresses (like `192.0.2.1`) that computers use to locate web servers. This translation is crucial for users to access your web application using its domain name rather than a complex IP address.

**TTL (Time To Live)**

In web applications, TTL most commonly refers to a value that dictates how long a piece of data should be cached. This applies to DNS records (how long a domain name resolution is cached by resolvers/browsers) and HTTP Caching headers (e.g., `Cache-Control: max-age`), which control how long browsers or CDNs cache web content like images, CSS, or API responses.

**Static Resource**

In web applications, a static resource is any file that is delivered to the user's browser without being modified or generated by the server on-the-fly for each request. Common examples include HTML files (if not template-generated), CSS stylesheets, JavaScript files, images, fonts, and videos. These files are often ideal for caching by browsers and CDNs to improve performance.

**TCP (Transmission Control Protocol)**

TCP is a core internet protocol that ensures reliable, ordered, and error-checked delivery of data between applications. In web applications, TCP forms the backbone for HTTP/HTTPS, making sure web pages and API communications arrive correctly and completely between servers and browsers.

**HTTP (Hypertext Transfer Protocol)**

HTTP is an application-layer protocol used for transmitting hypermedia documents, such as HTML, and is the foundation of data communication for the World Wide Web. It operates as a stateless request-response protocol where clients (e.g., web browsers) send requests to servers, which then send back responses containing the requested resources or an error message.

**HTTPS (Hypertext Transfer Protocol Secure)**

HTTPS is the secure version of HTTP, where communications between the client (e.g., web browser) and the server are encrypted using Transport Layer Security (TLS). This ensures that data exchanged, such as login credentials, personal information, and Browse activity, is protected from eavesdropping and tampering, providing confidentiality, authentication, and integrity.

**Dynamic Resource**

A dynamic resource is content that is generated by the server on-the-fly for each specific request, often based on user interactions, database information, or other parameters. Unlike static resources, dynamic content can vary from one request to another, such as a personalized user profile page or current stock prices.

**Cache Hit**

A cache hit occurs when requested data is successfully found in the cache memory. This means the system can serve the data from the faster cache layer instead of having to retrieve it from the slower primary storage (the origin), resulting in quicker access and reduced load on the origin.

**Cache Miss**

A cache miss occurs when the requested data cannot be found in the cache memory. This necessitates fetching the data from the slower, primary storage (the origin), which increases latency for that request and potentially adds load to the origin server.

**Fresh Resource**

In caching, a "fresh resource" is a copy of a resource stored in a cache that is considered up-to-date and can be served directly to the client without needing to check with the origin server. This is typically determined by checking if the resource's Time To Live (TTL) or other cache-control directives indicate it has not yet expired.

**Stale Resource**

In caching, a "stale resource" is a copy of a resource stored in a cache that has expired according to its caching directives (e.g., its Time To Live has passed). Before serving a stale resource, a cache typically needs to revalidate it with the origin server, for instance, by making a conditional request to check if a newer version is available.

**Atomic Update**

An atomic update is an operation or a set of operations that is guaranteed to execute completely or not at all, ensuring that the system is never left in a partially updated state. If any part of an atomic update fails, any changes already made are rolled back, making the entire operation appear as a single, indivisible step.

**CQRS (Command Query Responsibility Segregation)**

CQRS is an architectural pattern that separates the models and operations for updating information (Commands) from those used to read information (Queries). This separation allows for individual scaling and optimization of read and write workloads, which often have different performance and consistency requirements.

**Reverse Proxy**

A reverse proxy is a server-side proxy that intercepts all communications from clients, forwarding requests to one or more backend servers. Clients are generally unaware they are communicating through this intermediary, which can provide benefits like load balancing, caching static content, SSL termination, and request routing.

**Authenticating requests**

Authenticating requests is the process of validating that a principal (a human or an application) issuing a request is genuinely who or what it claims to be. This is a crucial security step before authorizing access to resources or performing operations within a system.

**Rate limiting**

Rate limiting, also known as throttling, is a mechanism to control the amount of incoming traffic to a service by rejecting requests when a specific quota (e.g., requests per second per user) is exceeded. This helps protect services from overload, ensures fair usage, and can be used to enforce service tiers.

**Load balancing**

Load balancing is the process of distributing incoming network traffic or computational workloads across multiple servers or resources. This improves application responsiveness, increases availability by routing around failed servers, and enhances scalability by allowing more servers to handle the load.

**CDN (Content Delivery Network)**

A CDN is an overlay network of geographically distributed caching servers (reverse proxies) designed to improve the speed and reliability of delivering web content to users. By caching content closer to users, CDNs reduce latency, offload traffic from origin servers, and enhance resilience against traffic spikes.

**Overlay network**

An overlay network is a virtual network built on top of an existing network infrastructure (like the internet), using its own routing and protocols to achieve specific goals. CDNs are an example, creating optimized paths to reduce latency and improve data transfer performance over the standard internet routing.

**BGP (Border Gateway Protocol)**

BGP is the core routing protocol of the internet, responsible for exchanging routing information between autonomous systems (networks) and enabling them to decide the best paths for data packets to travel. It manages how packets get from one network to another by building and communicating routing tables across routers.

**Network Congestion**

Network congestion occurs when a network or a part of it is overloaded with more data traffic than it can handle efficiently. This leads to delays in packet delivery, increased latency, packet loss, and overall degradation of network performance.

**Network Bandwidth**

Network bandwidth refers to the maximum rate at which data can be transferred across a network path or interface, typically measured in bits per second (bps). It represents the data-carrying capacity of the network connection, influencing how quickly web pages load or files download.

**TCP window size**

In TCP, the window size refers to the amount of data that can be sent by a sender before an acknowledgment from the receiver is required. The "congestion window" is dynamically adjusted by TCP to manage data flow, prevent network congestion, and optimize throughput based on perceived network conditions.

**DDoS attack (Distributed Denial of Service attack)**

A Distributed Denial of Service (DDoS) attack is a malicious attempt to disrupt the normal traffic of a targeted server, service, or network by overwhelming it with a flood of internet traffic from multiple compromised computer systems. The primary goal is to make the online service unavailable to legitimate users by saturating its resources, like bandwidth or processing capacity.

**Internet Exchange Point (IXP)**

An Internet Exchange Point (IXP) is a physical location where Internet Service Providers (ISPs) and Content Delivery Networks (CDNs) connect their networks directly to exchange internet traffic. This allows them to reduce costs and improve routing efficiency by keeping local traffic local.

**Global DNS load balancing**

Global DNS load balancing is an advanced DNS service that distributes user traffic across multiple geographically dispersed servers or data centers. It makes routing decisions based on factors like the client's geographic location (inferred from IP), server health, load, and network latency to direct users to the optimal endpoint.

**Edge clusters**

Edge clusters, in the context of CDNs, are groups of caching servers deployed in multiple geographical locations closer to end-users. These clusters form the top caching layer of a CDN, storing copies of frequently accessed content to deliver it quickly to nearby users and reduce load on origin servers.

**Cache Hit ratio**

The cache hit ratio is a performance metric for a cache, representing the proportion of requests that are successfully served directly from the cache compared to the total number of requests made. A higher hit ratio indicates better cache efficiency, meaning more data is found in the cache, leading to faster response times and reduced load on the origin.

**Regional Caches (or intermediary caching clusters)**

Regional caches, also referred to as intermediary caching clusters within a CDN, are caching layers deployed in a smaller number of strategic geographical locations, sitting between edge clusters and the origin server. They cache a larger fraction of content than individual edge servers, helping to improve cache hit ratios for less frequently accessed content and further reducing requests to the origin server.

**CDN (Content Delivery Network)**

A CDN is an overlay network of geographically distributed caching servers (reverse proxies) architected around the design limitations of the network protocols that run the internet. By storing copies of web content closer to users, CDNs accelerate content delivery, reduce latency, and decrease the load on the origin server.

**Internet Service Provider (ISP)**

An Internet Service Provider (ISP) is a company that provides individuals, businesses, and other organizations with access to the internet and related services. ISPs manage the infrastructure required to connect users to the internet, which can include services like web hosting, email, and domain registration.
